# Model Based Prediction

## Basic idea
- Assume the data follow a probabilistic modell  
- Use Baye's theorem to identify optimal classifiers  

Pros:  
  - Can take advantage of structure of the data  
  - May be computationally convenient  
  - Are reasonably accurate on real problems  

Cons:  
  - Make additional assumptions about the data  
  - When the model is incorrect you may get reduced accuracy  
  
## Classifying using the model
  - Linear discriminant analysis  
  - Quadratic discriminant analysis  
  
## Example Iris Data
```{r}
data("iris")
library(ggplot2)
table(iris$Species)
inTrain <- createDataPartition(y = iris$Species, p = 0.7, list = FALSE)
training <- iris[inTrain, ]
testing <- iris[-inTrain, ]
dim(training); dim(testing)
```

## Build prediction
```{r}
library(caret)
modlda <- train(Species ~., data = training, method = "lda")
modnb <- train(Species ~., data = training, method = "nb")
plda = predict(modlda, testing)
pnb = predict(modnb, testing)
table(plda, pnb)
equalPredictions = (plda == pnb)
qplot(Petal.Width, Sepal.Width, colour = equalPredictions, data = testing)
```
